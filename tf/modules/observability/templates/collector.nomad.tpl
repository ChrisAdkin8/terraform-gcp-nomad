job "collector" {
  datacenters = ["dc1"]
  type        = "system"

  update {
    max_parallel     = 1
    min_healthy_time = "10s"
    healthy_deadline = "5m"
    auto_revert      = true
    stagger          = "30s"
  }

  group "agent" {
    restart {
      attempts = 3
      interval = "5m"
      delay    = "25s"
      mode     = "delay"
    }

    network {
      mode = "host"
      port "http" { static = 12344 }
    }

    volume "alloy_data" {
      type            = "host"
      source          = "alloy"
      read_only       = false
      attachment_mode = "file-system"
      access_mode     = "single-node-single-writer"
    }

    # =========================================================================
    # SIDECAR: Generate allocation metadata for Alloy
    # =========================================================================
    task "allocation-discovery" {
      driver = "docker"
      
      lifecycle {
        hook    = "prestart"
        sidecar = true
      }

      config {
        image   = "badouralix/curl-jq:latest"
        command = "/bin/sh"
        args    = ["-c", "while true; do /local/discover.sh; sleep 30; done"]
      }

      template {
        destination = "local/discover.sh"
        perms       = "755"
        change_mode = "noop"
        data        = <<-EOH
#!/bin/sh
set -e

NOMAD_ADDR="http://{{ env "attr.unique.network.ip-address" }}:4646"
NODE_ID="{{ env "node.unique.id" }}"
OUTPUT_DIR="/alloc/data"
OUTPUT_FILE="$${OUTPUT_DIR}/nomad-targets.json"
TEMP_FILE="$${OUTPUT_DIR}/nomad-targets.tmp"

# Fetch all allocations on this node
curl -sf "$${NOMAD_ADDR}/v1/node/$${NODE_ID}/allocations" | jq '[.[] | select(.ClientStatus == "running") as $alloc | 
  ($alloc.TaskStates | keys[]) as $task_name |
  [
    {
      "targets": ["localhost"],
      "labels": {
        "__path__": ("/opt/nomad/data/alloc/" + $alloc.ID + "/alloc/logs/" + $task_name + ".stdout.0"),
        "job": $alloc.JobID,
        "task": $task_name,
        "alloc_id": $alloc.ID,
        "stream": "stdout"
      }
    },
    {
      "targets": ["localhost"],
      "labels": {
        "__path__": ("/opt/nomad/data/alloc/" + $alloc.ID + "/alloc/logs/" + $task_name + ".stderr.0"),
        "job": $alloc.JobID,
        "task": $task_name,
        "alloc_id": $alloc.ID,
        "stream": "stderr"
      }
    }
  ]
] | flatten' > "$TEMP_FILE"

# Atomic move to avoid partial reads
mv "$TEMP_FILE" "$OUTPUT_FILE"

echo "$(date): Updated $${OUTPUT_FILE} with allocations from node $${NODE_ID}"
EOH
      }

      resources {
        cpu    = 50
        memory = 128
      }
    }

    # =========================================================================
    # MAIN TASK: Alloy collector
    # =========================================================================
    task "alloy" {
      driver = "docker"

      config {
        image        = "grafana/alloy:v1.11.3"
        ports        = ["http"]
        network_mode = "host"

        args = [
          "run",
          "--server.http.listen-addr=0.0.0.0:12344",
          "--storage.path=/var/lib/alloy/data",
          "local/config.alloy",
        ]

        mount {
          type     = "bind"
          target   = "/opt/nomad/data/alloc"
          source   = "/opt/nomad/data/alloc"
          readonly = true
        }

        mount {
          type     = "bind"
          target   = "/var/log"
          source   = "/var/log"
          readonly = true
        }

        mount {
          type     = "bind"
          target   = "/host/proc"
          source   = "/proc"
          readonly = true
        }

        mount {
          type     = "bind"
          target   = "/host/sys"
          source   = "/sys"
          readonly = true
        }
      }

      volume_mount {
        volume      = "alloy_data"
        destination = "/var/lib/alloy/data"
        read_only   = false
      }

      template {
        destination = "local/config.alloy"
        change_mode = "restart"
        data        = <<-EOH
// ============================================================================
// LOGGING
// ============================================================================

logging {
  level  = "info"
  format = "logfmt"
}

// ============================================================================
// ALLOCATION DISCOVERY FROM SIDECAR
// ============================================================================

// Read targets generated by the allocation-discovery sidecar
// This provides job/namespace metadata for ALL allocations on this node
discovery.file "nomad_allocations" {
  files = ["/alloc/data/nomad-targets.json"]
  refresh_interval = "30s"
}

// ============================================================================
// NOMAD LOG COLLECTION (ALL ALLOCATIONS)
// ============================================================================

loki.source.file "nomad_logs" {
  targets    = discovery.file.nomad_allocations.targets
  forward_to = [loki.process.add_metadata.receiver]
}

// ============================================================================
// ADD ADDITIONAL METADATA
// ============================================================================

loki.process "add_metadata" {
  stage.static_labels {
    values = {
      node       = "{{ env "node.unique.name" }}",
      source     = "nomad",
      datacenter = "dc1",
    }
  }

  forward_to = [loki.write.loki.receiver]
}

// ============================================================================
// SYSTEM LOGS (OPTIONAL)
// ============================================================================

local.file_match "system_logs" {
  path_targets = [
    {__path__ = "/var/log/syslog"},
    {__path__ = "/var/log/messages"},
    {__path__ = "/var/log/nomad*.log"},
    {__path__ = "/var/log/consul*.log"},
  ]
}

loki.source.file "system_logs" {
  targets    = local.file_match.system_logs.targets
  forward_to = [loki.process.system_labels.receiver]
}

loki.process "system_labels" {
  stage.static_labels {
    values = {
      node   = "{{ env "node.unique.name" }}",
      source = "system",
    }
  }

  forward_to = [loki.write.loki.receiver]
}

// ============================================================================
// SEND LOGS TO LOKI
// ============================================================================

loki.write "loki" {
  endpoint {
    url = "http://gateway-api.${host_url_suffix}:8080/loki/api/v1/push"

    batch_wait = "1s"
    batch_size = "100KiB"

    retry_on_http_429 = true
  }

  external_labels = {
    collector_node = "{{ env "node.unique.name" }}",
  }
}
EOH
      }

      resources {
        cpu    = 256
        memory = 256
      }

      service {
        name = "collector"
        port = "http"

        tags = [
          "monitoring", "alloy", "logs",
          "traefik.enable=true",
          "traefik.http.routers.collector.rule=Host(`collector.${host_url_suffix}`)",
          "traefik.http.routers.collector.entrypoints=http",
          "traefik.http.services.collector.loadbalancer.server.port=12344",
        ]

        check {
          type     = "http"
          path     = "/-/healthy"
          interval = "30s"
          timeout  = "5s"

          check_restart {
            limit           = 3
            grace           = "30s"
            ignore_warnings = false
          }
        }
      }

      kill_timeout = "30s"
      kill_signal  = "SIGINT"
    }
  }
}